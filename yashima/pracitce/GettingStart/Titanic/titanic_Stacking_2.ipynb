{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"titanic_Stacking_2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"uGxp_ZC-diND","colab_type":"code","colab":{}},"source":["!pip install optuna\n","!pip install featuretools\n","!pip install heamy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rSO1MloFeEbB","colab_type":"code","colab":{}},"source":["!unzip titanic.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zx9NGhOteTxL","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","import optuna\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier , AdaBoostClassifier, ExtraTreesClassifier\n","from xgboost import XGBClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.linear_model import Perceptron\n","from sklearn.svm import SVC\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EjXOqOtlecYr","colab_type":"code","colab":{}},"source":["\n","'''\n","データのロード\n","'''\n","train = pd.read_csv(\"train.csv\")      # (891, 12)\n","test = pd.read_csv(\"test.csv\")        # (418, 11)\n","\n","full_data = pd.concat([train,test])\n","\n","train_len = len(train)      # 891\n","test_len = len(test)        # 418"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VFHVak_fDIl","colab_type":"code","colab":{}},"source":["def missing_table(df):      # データの欠損を計算\n","    null_val = df.isnull().sum()\n","    percent = 100 * df.isnull().sum()/len(df)\n","    missing_table = pd.concat([null_val, percent], axis=1)\n","    missing_table_ren_columns = missing_table.rename(\n","        columns = {0:\"欠損数\", 1:\"%\"}\n","    )\n","    return missing_table_ren_columns\n","\n","# print(missing_table(train))\n","# print(missing_table(test))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9yqZnZzAs0On","colab_type":"code","colab":{}},"source":["train.nunique()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_PqYLK2KgL7U","colab_type":"code","colab":{}},"source":["'''\n","データの前処理\n","'''\n","# 欠損値の補正\n","test[\"Fare\"] = test[\"Fare\"].fillna(test[\"Fare\"].median())\n","train['Embarked'] = train['Embarked'].fillna('S')\n","# full_data[\"Fare\"] = full_data[\"Fare\"].fillna(full_data[\"Fare\"].median())\n","# full_data['Embarked'] = full_data['Embarked'].fillna('S')\n","\n","# 名前の敬称を抽出\n","for i in range(len(train)):\n","  train[\"Name\"][i] = train[\"Name\"][i].split('.')[0].split(', ')[1]\n","for i in range(len(test)):\n","  test[\"Name\"][i] = test[\"Name\"][i].split('.')[0].split(', ')[1]\n","# for i in range(len(full_data)):\n","#   full_data[\"Name\"][i] = full_data[\"Name\"][i].split('.')[0].split(', ')[1]\n","full_data = pd.concat([train,test])\n","\n","# 家族数を計算\n","# train['family'] = train['SibSp'] + train['Parch']\n","# test['family'] = test['SibSp'] + test['Parch']\n","full_data['family'] = full_data['SibSp'] + full_data['Parch']\n","\n","# ダミーデータを生成\n","def add_dummy(df):\n","    df['Pclass'] = df['Pclass'].astype(np.str)\n","    temp = pd.get_dummies(df[['Sex','Embarked','Pclass','Name']], drop_first = False)\n","    temp['PassengerId'] = df['PassengerId']\n","    return pd.merge(df, temp)\n","# train = add_dummy(train)\n","# test = add_dummy(test)\n","full_data = add_dummy(full_data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N9XWS1LE_NDH","colab_type":"code","colab":{}},"source":["x_train_map = full_data[:len(train)].drop(columns=['PassengerId','Name','Sex', 'Ticket','Embarked','Age','Cabin','Pclass'])\n","x_train = full_data[:len(train)].drop(columns=['Survived', 'PassengerId','Name','Sex', 'Ticket','Embarked','Age','Cabin','Pclass'])\n","x_test = full_data[len(train):].drop(columns=['Survived','PassengerId','Name','Sex', 'Ticket','Embarked','Age','Cabin','Pclass'])\n","y_train = full_data[:len(train)]['Survived']\n","\n","# x_train_demo = full_data.loc[:,[\n","#     'family',\n","#     'Fare',\n","#     'Sex_female',\n","#     'Sex_male',\n","#     'Pclass_1',\n","#     'Pclass_3',\n","#     'Name_Miss',\n","#     'Name_Mr'\n","# ]]\n","# x_train_demo = x_train_demo[:len(train)]\n","# x_test_demo = full_data.loc[:,[\n","#     'family',\n","#     'Fare',\n","#     'Sex_female',\n","#     'Sex_male',\n","#     'Pclass_1',\n","#     'Pclass_3',\n","#     'Name_Miss',\n","#     'Name_Mr'\n","# ]]\n","# x_test_demo = x_test_demo[len(train):]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AEL91bhzmbT9","colab_type":"code","colab":{}},"source":["corrmat = x_train_map.corr()\n","f, ax = plt.subplots(figsize=(20,12))\n","sns.heatmap(corrmat, vmax=.8, annot = True, center = 0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fzbz2MRm8x_u","colab_type":"code","colab":{}},"source":["'''\n","特徴量の選択\n","'''\n","from boruta_py import BorutaPy\n","\n","model = RandomForestClassifier(max_depth=5)\n","feat_selector = BorutaPy(\n","    model,\n","    n_estimators='auto',\n","    two_step= True,\n","    verbose=2,\n","    random_state=42,\n","    perc=80,\n","    max_iter=100\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Iy6yx4qU-nKd","colab_type":"code","colab":{}},"source":["feat_selector.fit(x_train.values, y_train.values)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QnJ-OGbQBGbd","colab_type":"code","colab":{}},"source":["x_train_selected = x_train.iloc[:,feat_selector.support_]\n","x_test_selected = x_test.iloc[:,feat_selector.support_]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gif0NlKlTchm","colab_type":"code","colab":{}},"source":["# k分割交差検証\n","from sklearn.model_selection import cross_val_score\n","\n","def kfold(model, x, y, cv):\n","  data_s = pd.concat([x, y], axis=1)\n","  data_s = data_s.sample(frac=1)\n","  x_s = data_s.drop(columns=['Survived'])\n","  y_s = data_s['Survived'].as_matrix()\n","  scores = cross_val_score(model, x_s, y_s, cv=cv)\n","  print('Cross-Validation scores: {}'.format(scores))\n","  print('Average score: {}'.format(np.mean(scores)))\n","  return float(format(np.mean(scores)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pTI48HPIP5-Y","colab_type":"code","outputId":"aa27e4e7-7872-4ec7-f5a4-b0fcdaebecd0","executionInfo":{"status":"ok","timestamp":1556880928440,"user_tz":-540,"elapsed":457,"user":{"displayName":"トムー","photoUrl":"","userId":"01084465765645554068"}},"colab":{"base_uri":"https://localhost:8080/","height":91}},"source":["'''\n","モデルの構築(Stacking)\n","'''\n","from heamy.dataset import Dataset\n","from heamy.estimator import Regressor\n","from heamy.pipeline import ModelsPipeline\n","from sklearn.linear_model import LinearRegression\n","\n","# data_s = pd.concat([x_train_selected, y_train], axis=1)\n","data_s = pd.concat([x_train, y_train], axis=1)\n","data_s = data_s.sample(frac=1)\n","x_s = data_s.drop(columns=['Survived'])\n","y_s = data_s['Survived'].as_matrix()\n","(x_s, x_val, y_s, y_val) = train_test_split(x_s, y_s, test_size=0, random_state=666)\n","\n","# dataset = Dataset(x_s, y_s, x_val)\n","dataset = Dataset(x_s, y_s, x_test)"],"execution_count":254,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: FutureWarning:\n","\n","Method .as_matrix will be removed in a future version. Use .values instead.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"AtM6zawgPE3E","colab_type":"code","colab":{}},"source":["rf_params = {\n","    'n_jobs': -1,\n","    'n_estimators': 1000,\n","    'warm_start': True,\n","    'max_depth': 6,\n","    'min_samples_leaf': 2,\n","    'max_features' : 'sqrt',\n","    'verbose': 0,\n","    'random_state':10\n","}\n","\n","#Extra Trees Parameters\n","et_params = {\n","    'n_jobs': -1,\n","    'n_estimators':1000,\n","    'max_depth': 9,\n","    'min_samples_split': 6,\n","    'min_samples_leaf': 4,\n","    'verbose': 0,\n","    'random_state':10\n","}\n","\n","#AdaBoost parameters\n","ada_params = {\n","    'n_estimators': 1000,\n","    'learning_rate' : 0.75,\n","    'random_state':10\n","}\n","\n","#Gradient Boosting parameters\n","gb_params = {\n","    'n_estimators': 1000,\n","    'max_depth': 5,\n","    'min_samples_leaf': 2,\n","    'verbose': 0,\n","    'random_state':10\n","}\n","\n","#Support Vector Classifier parameters \n","svc_params = {\n","    'kernel' : 'linear',\n","    'C' : 0.025,\n","    'random_state':10\n","    }\n","    \n","#Perceptron Parameters\n","per_params = {\n","    'n_iter':50,\n","    'n_jobs':-1,\n","    'random_state':10\n","    }\n","    \n","#XGBoost Parameters\n","xgb_params = {\n","    'n_estimators':2000,\n","    'learning_rate':0.1,\n","    'max_depth':3,\n","    'min_child_weight':2, \n","    'gamma':0.2,\n","    'subsample':0.85,\n","    'colsample_bytree':0.5,\n","    'objective':'binary:logistic',\n","    'scale_pos_weight':1,\n","    'reg_alpha':1.05,\n","    'seed':10\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dvrPAoj-sALM","colab_type":"code","colab":{}},"source":["# アンサンブルに使うモデルの定義\n","models = [\n","    Regressor(dataset=dataset, estimator=RandomForestClassifier, parameters=rf_params, name='rf'),\n","#     Regressor(dataset=dataset, estimator=KNeighborsClassifier, name='kn'),\n","    Regressor(dataset=dataset, estimator=ExtraTreesClassifier, parameters=et_params, name='et'),\n","    Regressor(dataset=dataset, estimator=AdaBoostClassifier, parameters=ada_params, name='ada'),\n","    Regressor(dataset=dataset, estimator=SVC, parameters=svc_params, name='svc'),\n","    Regressor(dataset=dataset, estimator=Perceptron, parameters=per_params, name='per'),\n","    Regressor(dataset=dataset, estimator=XGBClassifier, parameters=xgb_params, name='xgb'),\n","#     Regressor(dataset=dataset, estimator=GradientBoostingClassifier, parameters=gb_params, name='gb')\n","]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PejcqXmrws8d","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":835},"outputId":"7448654a-776a-4dc7-f291-a2cccb19a4af","executionInfo":{"status":"ok","timestamp":1556881009697,"user_tz":-540,"elapsed":80201,"user":{"displayName":"トムー","photoUrl":"","userId":"01084465765645554068"}}},"source":["# pipelineを定義、2nd levelデータセットの作成\n","pipeline = ModelsPipeline(*models)\n","stack_ds = pipeline.stack(k=10, seed=0)"],"execution_count":257,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning:\n","\n","n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n","\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning:\n","\n","n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n","\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning:\n","\n","n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n","\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning:\n","\n","n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n","\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning:\n","\n","n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n","\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning:\n","\n","n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n","\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning:\n","\n","n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n","\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning:\n","\n","n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n","\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning:\n","\n","n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n","\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning:\n","\n","n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n","\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning:\n","\n","n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"TXKa6knjzWRR","colab_type":"code","colab":{}},"source":["# modelを作ってvalidation\n","stacker = Regressor(dataset=stack_ds, estimator=ExtraTreesClassifier, parameters={\n","    'n_estimators':2000, \n","    'max_depth':4, \n","    'min_samples_split':6, \n","    'min_samples_leaf':2, \n","    'max_features':0.8, \n","    'n_jobs':-1, \n","    'random_state':10, \n","    'verbose':0\n","})\n","y_trues, y_preds = stacker.validate(k=10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SObZK40B_G9r","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":203},"outputId":"c34f98d3-bea2-41ca-d94c-0784d9d14e64","executionInfo":{"status":"ok","timestamp":1556881204614,"user_tz":-540,"elapsed":5417,"user":{"displayName":"トムー","photoUrl":"","userId":"01084465765645554068"}}},"source":["for i in range(len(y_trues)):\n","  print(\"Accuracy_v:\",accuracy_score(y_trues[i], np.round(y_preds[i])))"],"execution_count":262,"outputs":[{"output_type":"stream","text":["Accuracy_v: 0.8777777777777778\n","Accuracy_v: 0.797752808988764\n","Accuracy_v: 0.8426966292134831\n","Accuracy_v: 0.7640449438202247\n","Accuracy_v: 0.8539325842696629\n","Accuracy_v: 0.8426966292134831\n","Accuracy_v: 0.8314606741573034\n","Accuracy_v: 0.8314606741573034\n","Accuracy_v: 0.7752808988764045\n","Accuracy_v: 0.8314606741573034\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eS6nCfbk0ukF","colab_type":"code","colab":{}},"source":["pred_stacker = stacker.predict()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R53aDSWO6oRO","colab_type":"code","colab":{}},"source":["pred_stacker = np.round(pred_stacker).astype(int)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d6KrQjRA5rmt","colab_type":"code","colab":{}},"source":["'''\n","評価\n","'''\n","print(\"Accuracy_v:\",accuracy_score(pred_stacker, y_val))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v0ozai65Sp8d","colab_type":"code","colab":{}},"source":["'''\n","提出\n","'''\n","from datetime import datetime, timedelta, timezone\n","JST = timezone(timedelta(hours=+9), 'JST')\n","ts = datetime.now(JST).strftime('%y%m%d%H%M')\n","\n","y_test = pred_stacker\n","\n","test[\"Survived\"] = y_test.astype(np.int)\n","test[[\"PassengerId\",\"Survived\"]].to_csv(('submit_'+ts+'_stacker.csv'),index=False)"],"execution_count":0,"outputs":[]}]}